{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for test_cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "158 matrices have been created\n",
      "\n",
      "The initial matrix store can be seen in ../dat/out/preload.Real.store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "# Copyright 2014, Institute for Defense Analyses                #\n",
    "# 4850 Mark Center Drive, Alexandria, VA; 703-845-2500          #\n",
    "# This material may be reproduced by or for the US Government   #\n",
    "# pursuant to the copyright license under the clauses at DFARS  #\n",
    "# 252.227-7013 and 252.227-7014.                                #\n",
    "#                                                               #\n",
    "# LARC : Linear Algebra via Recursive Compression               #\n",
    "# Authors:                                                      #\n",
    "#   - Steve Cuccaro (IDA-CCS)                                   #\n",
    "#   - John Daly (LPS)                                           #\n",
    "#   - John Gilbert (UCSB, IDA adjunct)                          #\n",
    "#   - Jenny Zito (IDA-CCS)                                      #\n",
    "#                                                               #\n",
    "# Additional contributors are listed in \"LARCcontributors\".   #\n",
    "#                                                               #\n",
    "# POC: Jennifer Zito <jszito@super.org>                         #\n",
    "# Please contact the POC before disseminating this code.        #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "import os\n",
    "import sys \n",
    "sys.path.append(\"../../src\")\n",
    "import pylarc\n",
    "import numpy as np\n",
    "from ctypes import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib nbagg\n",
    "\n",
    "# print \"This code tests some basic matrix building and reading routines\\n\"\n",
    "# initialize larc\n",
    "mat_store_exp = 15\n",
    "op_store_exp = 5\n",
    "max_level = 10\n",
    "rnd_sig_bits = -1   # default value\n",
    "trunc_to_zero_bits = -1  # default value\n",
    "pylarc.create_report_thread(1800)\n",
    "pylarc.initialize_larc(mat_store_exp,op_store_exp,max_level,rnd_sig_bits,trunc_to_zero_bits)\n",
    "\n",
    "# Define string for using in formating filenames\n",
    "if pylarc.cvar.scalarTypeDef == 'i':\n",
    "    scalarType = \"Integer\"\n",
    "elif pylarc.cvar.scalarTypeDef == 'c':\n",
    "    scalarType = \"Complex\"\n",
    "elif pylarc.cvar.scalarTypeDef == 'r':\n",
    "    scalarType = \"Real\"\n",
    "else:\n",
    "    raise Exception('scalarTypeDef %s was not handled.'%(pylarc.cvar.scalarTypeDef,))\n",
    "\n",
    "# Calculate number of matrices created, then print part of matrix store\n",
    "num_matrices_made = pylarc.num_matrices_created()\n",
    "print \"\\n%d matrices have been created\" %num_matrices_made\n",
    "end = num_matrices_made - 1\n",
    "filename = \"../dat/out/preload.%s.store\" %scalarType\n",
    "pylarc.matrix_store_info_to_file(0,end,filename,\"After preload with parameters: 26, 24, 10.\")\n",
    "print \"\\nThe initial matrix store can be seen in %s\\n\" %filename\n",
    "\n",
    "# type control return to execute this code block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    # SAMPLE ACTIVITES WITH MATRIX INPUT AND OUTPUT, & LEARNING PYTHON\n",
    "    verbose = 0\n",
    "    \n",
    "    # reading prewritten nonsquare matrices, and naive printout\n",
    "    filename = \"../dat/in/sample.1.2.%s.json\" %scalarType\n",
    "    sampmID = pylarc.matrix_read_json_file_matrixID(filename)\n",
    "    if verbose:\n",
    "        print \"Read in json file %s\\n\" %filename\n",
    "        print \"Which is the matrix with matrixID %d\\n\" %sampmID\n",
    "        print \"Printing this matrix in standard format gives:\\n\"\n",
    "        pylarc.print_matrix_naive_by_matrixID(sampmID)\n",
    "        print \"\\n\"\n",
    "    \n",
    " \n",
    "    # create a matrix in python for various scalar types: int, complex, real\n",
    "    if pylarc.cvar.scalarTypeDef == 'i':\n",
    "        a = np.matrix([[1, 3, 5, 6],\n",
    "                       [8, 6, 3, 1],\n",
    "                       [-9, 11, 13, 15],\n",
    "                       [16, 13, 12, 10]])\n",
    "    elif pylarc.cvar.scalarTypeDef == 'c':\n",
    "        a = np.matrix([[1+2j, 3+4j, 5+6j, 7+8j],\n",
    "                       [8+7j, 6+5j, 3+4j, 1+2j],\n",
    "                       [9+10j, 11+12j, 13+14j, 15+16j],\n",
    "                       [16+15j, 14+13j, 12+11j, 10+9j]])\n",
    "    elif pylarc.cvar.scalarTypeDef == 'r':\n",
    "        a = np.matrix([[1, 3, .5, 6],\n",
    "                       [8, 6, 3, .1],\n",
    "                       [-9, 11, 13, 1.5],\n",
    "                       [16, 13, 12, 10]])\n",
    "    else:\n",
    "        raise Exception('Do not know how to build matrix for type %s.'%(pylarc.cvar.scalarTypeDef,))\n",
    "    if verbose:\n",
    "        a\n",
    "\n",
    "        \n",
    "    # convert python matrix into an array by reading off each row in turn (row major format)\n",
    "    alist = a.reshape(-1).tolist()[0]\n",
    "    arr = pylarc.buildArray(alist)\n",
    "    if verbose:\n",
    "        print 'arr:', pylarc.str_scalarTypeArray(arr, len(alist))\n",
    "        \n",
    "        \n",
    "    # Use C routing row_major_list_to_store_matrixID to\n",
    "    # interpret the array as a row major list of a matrix\n",
    "    # enter it into the matrix store and then return \n",
    "    # the matrixID of the stored matrix.\n",
    "    if verbose:\n",
    "        print \"Using row_major_list_to_store on data entered from python\\n\"\n",
    "    # parameters for entering the python array into the store\n",
    "    level = 2\n",
    "    dim_whole = 2**level\n",
    "    # creating or finding the matrix associated with the array\n",
    "    serial = pylarc.row_major_list_to_store_matrixID(arr, level, level, dim_whole)\n",
    "    if verbose:\n",
    "        pylarc.print_matrix_naive_by_matrixID(serial)\n",
    "        print \"\\n\"\n",
    "   \n",
    "\n",
    "    # Make a parent matrix from four copies of the a matrix \n",
    "    # as specified by its matrixID\n",
    "    if verbose:\n",
    "        print \"Creating matrix from matrix_get_matrixID_from_panel on panel input and writing json file\\n\"\n",
    "    panel = [serial]*4   # alternatively panel=[serial,serial,serial,serial]\n",
    "    serial_parent = pylarc.matrix_get_matrixID_from_panel(serial,serial,serial,serial,3,3)\n",
    "    if verbose:\n",
    "        pylarc.print_matrix_naive_by_matrixID(serial_parent)\n",
    "        \n",
    "        \n",
    "    # Writing a matrix to a file in our compressed form (json file)\n",
    "    filename = \"../dat/out/testfile.%s.json\" %scalarType\n",
    "    pylarc.matrix_write_json_file_matrixID(serial_parent,filename)\n",
    "    if verbose:\n",
    "        print \"Wrote a matrix constructed from four panel submatrices to the file %s\\n\" %filename\n",
    " \n",
    "\n",
    "    #  Read in a compressed matrix (for the Toffoli gate)    \n",
    "    filename = \"../dat/in/toffoli.%s.json\" %scalarType\n",
    "    toffmID = pylarc.matrix_read_json_file_matrixID(filename)\n",
    "    if verbose:\n",
    "        print \"Reading matrix file in compressed form (using json format)\\n\"\n",
    "        print \"   for the Toffoli gate from the file %s\\n\" %filename\n",
    "        pylarc.print_matrix_naive_by_matrixID(toffmID)\n",
    "        print \"\\n\"\n",
    "\n",
    "    # Reading and writing matrices in various formats\n",
    "    if verbose:\n",
    "        print \"Matrices can be read or stored in many formats\\n\"\n",
    "        print \"  if small they can be written or read as row major matrices (rmm)\\n\"\n",
    "        print \"  if small they can be written in naive format\\n\"\n",
    "        print \"  if large they can be written or read in compressed format (json)\\n\"\n",
    "        print \"Testing reading row major matrix format and writing files in json and naive format.\\n\"\n",
    "    filename_rmm = \"../dat/in/sample.1.1.%s.rmm\" %scalarType\n",
    "    filename_naive = \"../dat/out/sample.1.1.%s.naive\" %scalarType\n",
    "    filename_json = \"../dat/out/sample.1.1.%s.json\" %scalarType   \n",
    "    samplemID = pylarc.read_row_major_matrix_from_file_matrixID(filename_rmm)\n",
    "    pylarc.print_matrix_to_file_naive_by_matrixID(samplemID,filename_naive)\n",
    "    pylarc.matrix_write_json_file_matrixID(samplemID,filename_json)\n",
    "    if verbose:\n",
    "        print \"Printing out the rrm sample matrix in naive format to screen\\n\"\n",
    "        pylarc.print_matrix_naive_by_matrixID(samplemID)\n",
    "        print \"Testing reading row major nonsquare matrices and writing files in json and naive format.\\n\"\n",
    "    filename_rmm = \"../dat/in/sample.1.2.%s.rmm\" %scalarType\n",
    "    filename_naive = \"../dat/out/sample.1.2.%s.naive\" %scalarType\n",
    "    filename_json = \"../dat/out/sample.1.2.%s.json\" %scalarType\n",
    "    samplemID = pylarc.read_row_major_matrix_from_file_matrixID(filename_rmm)\n",
    "    pylarc.print_matrix_to_file_naive_by_matrixID(samplemID,filename_naive)\n",
    "    pylarc.matrix_write_json_file_matrixID(samplemID,filename_json)\n",
    "    if verbose:\n",
    "        print \"Printing out the nonsquare rrm sample matrix in naive format to screen\\n\"\n",
    "        pylarc.print_matrix_naive_by_matrixID(samplemID)\n",
    "        print \"Test printing nonzeroes to file.\\n\"\n",
    "    filename_rmm = \"../dat/in/sample.1.3.%s.rmm\" %scalarType\n",
    "    filename_nonzeros = \"../dat/out/sample.1.3.%s.nonzeros\" %scalarType\n",
    "    filename_json = \"../dat/out/sample.1.3.%s.json\" %scalarType\n",
    "    samplemID = pylarc.read_row_major_matrix_from_file_matrixID(filename_rmm)\n",
    "    pylarc.print_matrix_nonzeros_to_file_by_matrixID(samplemID,filename_nonzeros)\n",
    "    pylarc.matrix_write_json_file_matrixID(samplemID,filename_json)\n",
    "    if verbose:\n",
    "        print \"Printing the matrix we are testing for printing out nonzero values\\n\"\n",
    "        pylarc.print_matrix_naive_by_matrixID(samplemID)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "192 matrices have been created\n"
     ]
    }
   ],
   "source": [
    "    verbose = 0\n",
    "    \n",
    "    # make CNOT\n",
    "    if verbose:\n",
    "        print \"\\nHere is the CNOT matrix\\n\"\n",
    "    CNOT_arr = pylarc.buildArray([1,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0])\n",
    "    CNOTmID = pylarc.row_major_list_to_store_matrixID(CNOT_arr,level,level,dim_whole)\n",
    "    pylarc.print_matrix_naive_by_matrixID(CNOTmID)\n",
    "\n",
    "    # Calculate number of matrices created, then print part of matrix store\n",
    "    num_matrices_made = pylarc.num_matrices_created()\n",
    "    print \"\\n%d matrices have been created\" %num_matrices_made\n",
    "    start = end + 1\n",
    "    end = num_matrices_made - 1\n",
    "    filename = \"../dat/out/cnot.%s.store\" %scalarType\n",
    "    pylarc.matrix_store_info_to_file(start,end,filename,\"Loaded CNOT\")\n",
    "\n",
    "    # build Zero matrices\n",
    "    if verbose:\n",
    "        print \"\\nHere is the level 2 zero matrix\\n\"\n",
    "    Z2_arr = pylarc.buildArray([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "    Z2mID = pylarc.row_major_list_to_store_matrixID(Z2_arr,level,level,dim_whole)\n",
    "    pylarc.print_matrix_naive_by_matrixID(Z2mID)\n",
    "\n",
    "    # build Identity matrices\n",
    "    if verbose:\n",
    "        print \"\\nHere is the level 2 identity matrix\\n\" \n",
    "    I2_arr = pylarc.buildArray([1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1])\n",
    "    I2mID = pylarc.row_major_list_to_store_matrixID(I2_arr,level,level,dim_whole)\n",
    "    pylarc.print_matrix_naive_by_matrixID(I2mID)\n",
    "\n",
    "    # build a TOFFOLI\n",
    "    if verbose:\n",
    "        print \"\\nHere is the 3 bit TOFFOLI matrix with target 3rd.\\n\"\n",
    "    # matrix_get_matrixID_from_panel is under construction\n",
    "    TOFFOLImID= pylarc.matrix_get_matrixID_from_panel(I2mID,Z2mID,Z2mID,CNOTmID,3,3)\n",
    "    pylarc.print_matrix_naive_by_matrixID(TOFFOLImID)\n",
    "    filename = \"../dat/out/toffoli.%s.naive\" %scalarType\n",
    "    pylarc.print_matrix_to_file_naive_by_matrixID(TOFFOLImID,filename)\n",
    "\n",
    "\n",
    "    #  PLAYING WITH PREWRITTEN NONSQUARE MATRIX\n",
    "    filename = \"../dat/in/sample.1.2.%s.json\" %scalarType\n",
    "    if verbose:\n",
    "        print \"About to test read %s\\n\" %filename\n",
    "    sampmID = pylarc.matrix_read_json_file_matrixID(filename)\n",
    "    if verbose:\n",
    "        print \"We read in the json file\\n\"\n",
    "    pylarc.print_matrix_naive_by_matrixID(sampmID)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"does scalarM1_val print?\"\n",
    "    scalarM1_val = -1\n",
    "    scalarM1mID = pylarc.matrix_get_matrixID_from_scalar(scalarM1_val)\n",
    "    pylarc.print_matrix_naive_by_matrixID(scalarM1mID)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"testing scalar_mult:\"\n",
    "    samp2mID = pylarc.scalar_mult_matrixID(scalarM1mID,sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp2mID)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"testing addition:\"\n",
    "    samp3mID = pylarc.matrix_add_matrixID(sampmID,samp2mID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp3mID)\n",
    "    \n",
    "    # save input matrixIDs for testing op store hash chains later\n",
    "    in1_test_summID = sampmID\n",
    "    in2_test_summID = samp2mID\n",
    "    \n",
    "    if verbose:\n",
    "        print \"testing adjoint:\"\n",
    "    samp3mID = pylarc.matrix_adjoint_matrixID(sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp3mID)\n",
    "    adjmID = samp3mID\n",
    "    \n",
    "    if verbose:\n",
    "        print \"testing non-square matrix mult:\"\n",
    "    samp4mID = pylarc.matrix_mult_matrixID(samp3mID,sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp4mID)\n",
    "    if verbose:\n",
    "        print \"\"\n",
    "    samp4mID = pylarc.matrix_mult_matrixID(sampmID,samp3mID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp4mID)\n",
    "    if verbose:\n",
    "        print \"testing kron product:\"\n",
    "    samp4mID = pylarc.kronecker_product_matrixID(sampmID,sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp4mID)\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print \"testing join:\"\n",
    "    samp4mID = pylarc.join_matrixID(sampmID,sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp4mID)\n",
    "    if verbose:\n",
    "        print \"testing stack:\"\n",
    "    samp4mID = pylarc.stack_matrixID(sampmID,sampmID)\n",
    "    pylarc.print_matrix_naive_by_matrixID(samp4mID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing to delete a matrix from the store.\n",
      "\n",
      "\n",
      "250 matrices have been created\n",
      "Previous range printed ended with matrixID 191\n",
      "\n",
      "Testing removal of matrix from the matrix store\n",
      "\n",
      "\n",
      "Deleting the toffoli matrix with matrixID 183 from store, which had been read from ../dat/out/temp.Real.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    ##  TESTING DELETION\n",
    "    print \"\\nPreparing to delete a matrix from the store.\\n\"\n",
    "    filename = \"../dat/out/temp.%s.json\" %scalarType\n",
    "    pylarc.matrix_write_json_file_matrixID(TOFFOLImID, filename)  \n",
    "    pylarc.matrix_read_json_file_matrixID(filename)\n",
    "\n",
    "    # Calculate number of matrices created, then print part of matrix store\n",
    "    num_matrices_made = pylarc.num_matrices_created()\n",
    "    print \"\\n%d matrices have been created\" %num_matrices_made\n",
    "    print \"Previous range printed ended with matrixID %d\\n\" %end\n",
    "    if (end == num_matrices_made-1) :\n",
    "        print \"Nothing new since last matrix store print\\n\"\n",
    "    else :\n",
    "        start = end + 1\n",
    "        end = num_matrices_made - 1\n",
    "        filename = \"../dat/out/toffoli.%s.store\" %scalarType\n",
    "        pylarc.matrix_store_info_to_file(start,end,filename,\"Loaded Toffoli\")\n",
    "\n",
    "    # get the hashID and print the hash chain corresponding to a matrix we are about to delete\n",
    "    hashID = pylarc.matrix_hashID_from_matrixID(toffmID)\n",
    "    comment = \"hash chain before removal\"\n",
    "    filename = \"../dat/out/hashChain.beforeMatrixRemove\"\n",
    "    pylarc.matrix_hash_chain_info_to_file(hashID, filename, comment)\n",
    "    \n",
    "    # Test deletion of a matrix\n",
    "    print \"Testing removal of matrix from the matrix store\\n\"\n",
    "    num_matrices_made =  pylarc.num_matrices_created()\n",
    "    end = num_matrices_made - 1\n",
    "    filename = \"../dat/out/toffoliYES.%s.store\" %scalarType\n",
    "    pylarc.matrix_store_info_to_file(0,end,filename,\"Before Removed Toffoli\")\n",
    "\n",
    "    pylarc.remove_matrix_from_mat_store_by_matrixID(toffmID)\n",
    "\t\n",
    "    filename = \"../dat/out/toffoliNO.%s.store\" %scalarType\n",
    "    filename_json = \"../dat/out/temp.%s.json\" %scalarType\n",
    "    print \"\\nDeleting the toffoli matrix with matrixID\", toffmID,\"from store, which had been read from %s\\n\"  %filename_json\n",
    "    pylarc.matrix_store_info_to_file(0,end,filename,\"Removed Toffoli\")\n",
    "\n",
    "    comment = \"hash chain after removal\"\n",
    "    filename = \"../dat/out/hashChain.afterMatrixRemove\"\n",
    "    pylarc.matrix_hash_chain_info_to_file(hashID, filename, comment)\n",
    "\n",
    "    pylarc.list_op_names()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid matrixID requested for op hash chain\n",
      "deleting matrix with matrixID 164\n",
      "The matrixID of matrix to be held is 202\n",
      "invalid matrixID requested for op hash chain\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # Test op store hash chains after deletion\n",
    "\t\n",
    "    # print ops store report before deletion of a matrix\n",
    "    # pylarc.op_store_report()\n",
    "    \n",
    "    # need op name to find the hash value so we can print op store hash chain\n",
    "    op_name = \"SUM\"\n",
    "    \n",
    "    # get hash for an operation record and print the hash chain\n",
    "    sum_hashID = pylarc.op_hashID_by_matrixIDs(in1_test_summID,in2_test_summID,op_name)\n",
    "    if (sum_hashID != -1):\n",
    "        pylarc.op_hash_chain_info_to_screen(sum_hashID,\"op hash chain before deletion\")\n",
    "    else:\n",
    "        print \"invalid matrixID requested for op hash chain\"\n",
    "    \n",
    "    # delete the first input matrix\n",
    "    pylarc.remove_matrix_from_mat_store_by_matrixID(in1_test_summID)\n",
    "    print \"deleting matrix with matrixID\", in1_test_summID\n",
    "    \n",
    "    # set a hold on a matrix by matrixID to see if it is immune to cleaning\n",
    "    print \"The matrixID of matrix to be held is\", adjmID\n",
    "    pylarc.set_hold_matrix_from_matrixID(adjmID)\n",
    "    \n",
    "    # clean the matrix store and print it again\n",
    "    pylarc.clean_matrix_store()\n",
    "    filename = \"../dat/out/toffoliNOcleaned.%s.store\" %scalarType\n",
    "    pylarc.matrix_store_info_to_file(0,end,filename,\"Removed Toffolli and cleaned matrix store\")\n",
    "\n",
    "    # clean the op store \n",
    "    # try one of three cleaning functions\n",
    "    \n",
    "    # clean a single op\n",
    "    # pylarc.clean_single_op_from_string(\"SUM\")\n",
    "    \n",
    "    # clean entire store\n",
    "    # pylarc.clean_entire_op_store() \n",
    "    \n",
    "    # clean entire store, one hash at a time\n",
    "    for hash in range(1<<op_store_exp):\n",
    "\t\tpylarc.clean_op_hash_chain(hash) \n",
    "    \n",
    "    # print same op hash chain again after deleting a matrix, holding a matrix and cleaning\n",
    "    if (sum_hashID != -1):\n",
    "        pylarc.op_hash_chain_info_to_screen(sum_hashID,\"op hash chain after deletion and cleaning\")\n",
    "    else:\n",
    "        print \"invalid matrixID requested for op hash chain\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 6, 4, 4, 4, 4, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_level\n",
    "diag_hist = []\n",
    "for i in range(max_level):\n",
    "    diag_hist.append(pylarc.get_diag_hist(i))\n",
    "diag_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 6, 4, 4, 4, 4, 3, 2, 2, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Earlier = [14, 6, 4, 4, 4, 4, 3, 2, 2, 1]\n",
    "\n",
    "Earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 6, 4, 4, 4, 4, 3, 2, 2, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.plot(Earlier)\n",
    "# plt.plot(diag_hist)\n",
    "# plt.show()\n",
    "Earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_store_exp is 15\n",
      "size_hash_table is 32768\n"
     ]
    }
   ],
   "source": [
    "mat_store_exp\n",
    "size_hash_table = 2**mat_store_exp\n",
    "matrix_hash_chain_count = []\n",
    "# pylarc.matrix_hash_chain_length(3)\n",
    "print \"mat_store_exp is %d\" %mat_store_exp\n",
    "print \"size_hash_table is %d\" %size_hash_table\n",
    "hash_hist = [0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(size_hash_table-1):\n",
    "    count = pylarc.matrix_hash_chain_length(i)\n",
    "    hash_hist[count] += 1\n",
    "    # if count > 0:\n",
    "    #    print \"The number of entries in the %d hash chain of the table is %d\"  %(i,count)\n",
    "    matrix_hash_chain_count.append(count)\n",
    "    \n",
    "size_hash_table\n",
    "if (size_hash_table <= 64):\n",
    "    # show the array of hash chain lengths\n",
    "    matrix_hash_chain_count\n",
    "# plt.plot(matrix_hash_chain_count)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32602, 165, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_hist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
